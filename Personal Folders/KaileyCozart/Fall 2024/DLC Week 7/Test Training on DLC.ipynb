{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76a7efb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc5...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n",
      "3.0.0rc5\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "print(deeplabcut.__version__)\n",
    "config_path = \"dlc_model-student-2023-07-26/config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339a7f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training with configuration:\n",
      "data:\n",
      "  colormode: RGB\n",
      "  inference:\n",
      "    normalize_images: True\n",
      "  train:\n",
      "    affine:\n",
      "      p: 0.5\n",
      "      rotation: 30\n",
      "      scaling: [1.0, 1.0]\n",
      "      translation: 0\n",
      "    collate:\n",
      "      type: ResizeFromDataSizeCollate\n",
      "      min_scale: 0.4\n",
      "      max_scale: 1.0\n",
      "      min_short_side: 128\n",
      "      max_short_side: 1152\n",
      "      multiple_of: 32\n",
      "      to_square: False\n",
      "    covering: False\n",
      "    gaussian_noise: 12.75\n",
      "    hist_eq: False\n",
      "    motion_blur: False\n",
      "    normalize_images: True\n",
      "device: auto\n",
      "metadata:\n",
      "  project_path: /storage/ice1/0/3/kcozart6/dlc_model-student-2023-07-26\n",
      "  pose_config_path: /storage/ice1/0/3/kcozart6/dlc_model-student-2023-07-26/dlc-models-pytorch/iteration-0/dlc_modelJul26-trainset95shuffle1/train/pose_cfg.yaml\n",
      "  bodyparts: ['nose', 'lefteye', 'righteye', 'spine1', 'spine2', 'spine3', 'backfin', 'leftfin', 'rightfin']\n",
      "  unique_bodyparts: []\n",
      "  individuals: ['fish1', 'fish2', 'fish3', 'fish4', 'fish5', 'fish6', 'fish7', 'fish8', 'fish9', 'fish10']\n",
      "  with_identity: False\n",
      "method: bu\n",
      "model:\n",
      "  backbone:\n",
      "    type: ResNet\n",
      "    model_name: resnet50_gn\n",
      "    output_stride: 16\n",
      "    freeze_bn_stats: True\n",
      "    freeze_bn_weights: False\n",
      "  backbone_output_channels: 2048\n",
      "  heads:\n",
      "    bodypart:\n",
      "      type: DLCRNetHead\n",
      "      predictor:\n",
      "        type: PartAffinityFieldPredictor\n",
      "        num_animals: 10\n",
      "        num_multibodyparts: 9\n",
      "        num_uniquebodyparts: 0\n",
      "        nms_radius: 5\n",
      "        sigma: 1.0\n",
      "        locref_stdev: 7.2801\n",
      "        min_affinity: 0.05\n",
      "        graph: [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [2, 3], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [4, 5], [4, 6], [4, 7], [4, 8], [5, 6], [5, 7], [5, 8], [6, 7], [6, 8], [7, 8]]\n",
      "        edges_to_keep: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "        apply_sigmoid: True\n",
      "        clip_scores: False\n",
      "      target_generator:\n",
      "        type: SequentialGenerator\n",
      "        generators: [{'type': 'HeatmapPlateauGenerator', 'num_heatmaps': 9, 'pos_dist_thresh': 17, 'heatmap_mode': 'KEYPOINT', 'gradient_masking': False, 'generate_locref': True, 'locref_std': 7.2801}, {'type': 'PartAffinityFieldGenerator', 'graph': [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [2, 3], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [3, 4], [3, 5], [3, 6], [3, 7], [3, 8], [4, 5], [4, 6], [4, 7], [4, 8], [5, 6], [5, 7], [5, 8], [6, 7], [6, 8], [7, 8]], 'width': 20}]\n",
      "      criterion:\n",
      "        heatmap:\n",
      "          type: WeightedBCECriterion\n",
      "          weight: 1.0\n",
      "        locref:\n",
      "          type: WeightedHuberCriterion\n",
      "          weight: 0.05\n",
      "        paf:\n",
      "          type: WeightedHuberCriterion\n",
      "          weight: 0.1\n",
      "      heatmap_config:\n",
      "        channels: [2048, 9]\n",
      "        kernel_size: [3]\n",
      "        strides: [2]\n",
      "      locref_config:\n",
      "        channels: [2048, 18]\n",
      "        kernel_size: [3]\n",
      "        strides: [2]\n",
      "      paf_config:\n",
      "        channels: [2048, 72]\n",
      "        kernel_size: [3]\n",
      "        strides: [2]\n",
      "      num_stages: 5\n",
      "net_type: resnet_50\n",
      "runner:\n",
      "  type: PoseTrainingRunner\n",
      "  gpus: None\n",
      "  key_metric: test.mAP\n",
      "  key_metric_asc: True\n",
      "  eval_interval: 10\n",
      "  optimizer:\n",
      "    type: AdamW\n",
      "    params:\n",
      "      lr: 0.0001\n",
      "  scheduler:\n",
      "    type: LRListScheduler\n",
      "    params:\n",
      "      lr_list: [[1e-05], [1e-06]]\n",
      "      milestones: [160, 190]\n",
      "  snapshots:\n",
      "    max_snapshots: 5\n",
      "    save_epochs: 25\n",
      "    save_optimizer_state: False\n",
      "train_settings:\n",
      "  batch_size: 32\n",
      "  dataloader_workers: 0\n",
      "  dataloader_pin_memory: False\n",
      "  display_iters: 500\n",
      "  epochs: 150\n",
      "  seed: 42\n",
      "Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)\n",
      "[timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "Data Transforms:\n",
      "  Training:   Compose([\n",
      "  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (1.0, 1.0), 'y': (1.0, 1.0)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),\n",
      "  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),\n",
      "  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n",
      "], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)\n",
      "  Validation: Compose([\n",
      "  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n",
      "], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)\n",
      "Using custom collate function: {'type': 'ResizeFromDataSizeCollate', 'min_scale': 0.4, 'max_scale': 1.0, 'min_short_side': 128, 'max_short_side': 1152, 'multiple_of': 32, 'to_square': False}\n",
      "\n",
      "Note: According to your model configuration, you're training with batch size 1 and/or ``freeze_bn_stats=false``. This is not an optimal setting if you have powerful GPUs.\n",
      "This is good for small batch sizes (e.g., when training on a CPU), where you should keep ``freeze_bn_stats=true``.\n",
      "If you're using a GPU to train, you can obtain faster performance by setting a larger batch size (the biggest power of 2 where you don't geta CUDA out-of-memory error, such as 8, 16, 32 or 64 depending on the model, size of your images, and GPU memory) and ``freeze_bn_stats=false`` for the backbone of your model. \n",
      "This also allows you to increase the learning rate (empirically you can scale the learning rate by sqrt(batch_size) times).\n",
      "\n",
      "Using 1472 images and 78 for testing\n",
      "\n",
      "Starting pose model training...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Execute the training function\n",
    "deeplabcut.train_network(config_path, shuffle=1, trainingsetindex=0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef1725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-DEEPLABCUT]",
   "language": "python",
   "name": "conda-env-.conda-DEEPLABCUT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
